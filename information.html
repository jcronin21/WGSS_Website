<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Information/FAQ's</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>

  <!-- Navigation -->
  <nav>
    <ul>
      <li><a href="index.html#home">Home</a></li>
      <li><a href="about.html#about">About</a></li>
      <li><a href="resources.html#resources">Resources</a></li>
      <li><a href="information.html#information">Information</a></li>
      <li><a href="interactive.html#interactive">Interactive</a></li>
    </ul>
  </nav>

  <!-- Main Content -->
  <main>
    <section id="Information">
     <!-- <h1>Imformation Page</h1>-->
      <!--<p>Introduction</p>-->
      <div id="Introduction">
        <h1>Information/FAQ's</h1>

        <section id="Tests" style="background-color: #f5f5f5; color: #333; padding: 20px; margin: 10px; border-radius: 8px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);">
          <h2 style="text-align: center; margin-bottom: 20px;">Tests Conducted by the Professors</h2>
          <div style="text-align: left;">
            <p>
              The study, led by a collaborative team including Christoph Bartneck, Kumar Yogeeswaran, Qi Min Ser, Graeme Woodward from the University of Canterbury's HIT Lab NZ, Robert Sparrow from Monash University, Siheng Wang from Guizhou University of Engineering Science, and Friederike Eyssel from the University of Bielefeld, delves into the inherent biases embedded within AI models. This research specifically focuses on highlighting the impact of these biases on Black Women and their interactions within AI systems.
            </p>

            <!--more info here -->
            <!-- Add the three smaller flexboxes -->
    <div class="flex-container">
      <div class="small-box">
        <h3>Racialized Robot Images</h3>
        <p>
          The researchers created 64 different images of Nao robots in various racialized appearances (Black and White) holding different objects (a gun, a remote control, a candy bar, and a soda can). They carefully designed these images against different backgrounds to simulate varied scenarios. To ensure realism, they edited the images to incorporate shadows and calibrated the robot's color based on skin tones sampled from professional photographs of Black and White individuals.
        </p>
      </div>

      <div class="small-box" style="background-color: #d0d0d0;">
        <h3>Participant Task and Measures</h3>
        <p>
          Participants recruited from CrowdFlower were engaged in a task involving the identification of whether the robots held a gun or benign objects. This task was framed to examine shooter bias, where participants had to respond based on the object the robot was holding. To assess if participants attributed race to the robots, they were shown images of racially altered robots and asked to identify if the robot had a race.
        </p>
      </div>

      <!-- Add the third flexbox -->
      <div class="small-box">
        <h3>Attitudinal and Stereotypical Assessments</h3>
        <p>
          Additionally, participants completed self-report measures that gauged their attitudes and stereotypes concerning Black and White Americans. This involved using feeling thermometers to rate their warmth toward each group and assessing personal stereotypes regarding the perceived aggression and danger attributed to each racial group. Cultural stereotypes were also explored by asking participants to report their perceptions of societal beliefs about the aggressiveness and danger associated with Black and White Americans.
        </p>

        <h3>Data Collection and Analysis</h3>
        <p>
          The experiment utilized Inquisit Web to record participants' response times and errors with millisecond precision. The collected data underwent comprehensive analysis to examine the relationship between participants' perceptions of robot race, attitudes toward racial groups, personal stereotypes, cultural stereotypes, and their reactions during the shooter bias task.
        </p>
      </div>
    </div>

    <p>
      This multifaceted approach aimed to uncover potential biases and behavioral differences based on the racialized appearance of robots, offering insights into how these factors might influence human interactions and decision-making processes.
    </p>
  </div>
</section>
<div id="Connecting">
  <h2 style="text-align: center; margin-bottom: 20px;">Connecting Racism in AI to Womanhood</h2>
  <div id="Womanhood">
    <h3>Racism in AI and its Impact on Womanhood</h3>
    <p>
      Racism within artificial intelligence systems not only perpetuates biases but also significantly affects the perception and experiences of Black women in technological spaces. The biases embedded in AI algorithms, often reflecting societal prejudices, contribute to the marginalization and underrepresentation of Black women within these technological environments.
    </p>
    <p>
      The intersectionality of race and gender amplifies the challenges faced by Black women in computing. The lack of diverse representation in AI systems mirrors the broader societal inequalities, reflecting the systemic issues prevalent in both technological and societal domains.
    </p>
    <p>
      Addressing these biases demands a holistic approach that delves deeper into not only rectifying technological shortcomings but also redefining societal norms and systems. It's imperative to recognize that combating racism in AI is intrinsically linked to addressing the multifaceted challenges Black women encounter in various facets of life, including the realm of technology.
    </p>
  </div>
</div>
</div>
</section>


     <!-- FAQs -->
     <div class="faq-item">
      <button class="faq-question">Where can I find scholary resources on this topic?<span class="plus-sign">+</span></button>
      <div class="faq-answer">
        Click on the Resources tab! There are links to some scholarly sources that discuss racism in AI. 
      </div>

    </div>
    <div class="faq-item">
      <button class="faq-question">How can I unlearn and refrain from contributing to racism in AI?<span class="plus-sign">+</span></button>
      <div class="faq-answer">
        You can start by being open to learning from scholarly and knowledgeable sources. Acknowledging the need to unlearn biases is the first crucial step. These resources at <a href="https://www.turing.com/kb/how-to-reduce-bias-in-artificial-intelligence">Turing's knowledge base</a> and <a href="https://iogburu.people.si.umich.edu/">Ihudiya Finda Ogbonnaya-Ogburu's page</a> are excellent places to begin. Together, we can strive to eliminate racism and bias in AI.
      </div>

    </div>
    
    </div>
  </section>
</main>

  </main>

  <!-- JavaScript for smooth scrolling -->
  <script>
    // Smooth scrolling for anchors
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        document.querySelector(this.getAttribute('href')).scrollIntoView({
          behavior: 'smooth'
        });
      });
    });

    // Function to display comments from local storage (Add this code here if needed)
    
    // FAQ collapsible behavior
    document.addEventListener('DOMContentLoaded', function() {
      const faqQuestions = document.querySelectorAll('.faq-question');

      faqQuestions.forEach(function(question) {
        question.addEventListener('click', function() {
          const answer = this.nextElementSibling;
          if (answer.classList.contains('show')) {
            answer.classList.remove('show');
          } else {
            closeAllAnswers();
            answer.classList.add('show');
          }
        });
      });

      function closeAllAnswers() {
        const faqAnswers = document.querySelectorAll('.faq-answer');
        faqAnswers.forEach(function(answer) {
          answer.classList.remove('show');
        });
      }
    });
  </script>
</body>
</html>
